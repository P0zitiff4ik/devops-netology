[Задание](https://github.com/netology-code/bd-dev-homeworks/blob/main/06-db-06-troobleshooting/README.md)

------

## Задача 1

<details><summary>Описание</summary>

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести эту операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя;
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.

</details>

###### Решение:

1.1. Сначала надо найти запросы, выполняющиеся больше 3 минут (180 секунд) в базе данных `dbname` (или во всех, тогда строку с аргументом `ns` удаляем):

```sql
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 180 },
     "ns" : /^dbname\./
   }
)
```

1.2. Завершаем процесс командой `db.killOp(<opId>)`, где `<opId>` - id процесса из ответа на запрос выше.

[interrupt point]: ## "A point in an operation's lifecycle when it can safely abort. MongoDB only terminates an operation at designated interrupt points."

1.3. Решения проблемы с долгими (зависающими) запросами в MongoDB - использование метода `maxTimeMS()` при запросах. Метод устанавливает ограничение по времени для операции. Когда операция достигает указанного срока, MongoDB прерывает операцию в следующей [точке прерывания][interrupt point].

Также можно использовать и другие решения - шардинг, добавление или удаление индексов и т.д. в зависимости от контекста.  

---

## Задача 2

<details><summary>Описание</summary>

Перед выполнением задания познакомьтесь с документацией по [Redis latency troubleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?
</details>

###### Решение:

Вероятно при масштабировании копируются и TTL, тогда вначале может быть большое к-во ключей с одинаковым сроком жизни. В Redis механизм удаления ключей с истёкшим TTL осуществляется таким образом, что одномоментно удаляется 25% процентов таких ключей, при этом такая операция повторяется каждые 100 миллисекунд. В обычной ситуации это позволяет не сильно нагружать процессор и при этом достаточно быстро вычищать истёкшие ключи. Но если их значительно больше 25%, Redis может заблокироваться до того момента, когда он их не удалит достаточно, чтобы стало снова меньше этого значения.

---
 
## Задача 3

<details><summary>Описание</summary>

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения этой проблемы вы можете предложить?
</details>

###### Решение:
Изучаем логи и смотрим, есть ли в документации данная ошибка

[Описание ошибки в документации](https://dev.mysql.com/doc/refman/5.7/en/error-lost-connection.html)

Причины:
- Слишком "тяжёлый" запрос
- Слишком низкое значение `connect_timeout` (к-во секунд, которое MySQL ожидает инициализации запроса, прежде чем ответить `Bad handshake`)
- BLOB значений больше, чем установлено в `max_allowed_packet`

Решения:
- Увеличение `net_read_timeout` от 30 секунд (по умолчанию) до 60 секунд
- Если в ответе на запрос `SHOW GLOBAL STATUS LIKE 'Aborted_connects'` упоминается "reading authorization packet" и число постоянно увеличивается, то следует изменить значение `connect_timeout` на большее (от 10 секунд)
- Если в видим ошибку `ER_NET_PACKET_TOO_LARGE`, то увеличиваем `max_allowed_packet` в соответствии с самым большим размером BLOB кратно 1024 (но не больше 1ГБ)

---

## Задача 4

<details><summary>Описание</summary>

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили эту проблему?
</details>

###### Решение:

В двух словах, `Out-Of-Memory Killer` — это процесс, который завершает приложение, чтобы спасти ядро от сбоя при нехватке оперативной памяти. Он жертвует приложением, чтобы сохранить работу ОС.

Самый плохой вариант решения - отключить командой 

```shell
sudo -s sysctl -w vm.oom-kill = 0
```

Работает до первой перезагрузки. Чтобы отключить на постоянной основе, команда (от суперпользователя)
```shell
echo vm.oom-kill = 1 >>/etc/sysctl.conf
```

Но есть и другой способ. Linux может зарезервировать для процессов больше памяти, чем есть, но не выделять ее по факту, и этим поведением управляет параметр ядра Linux. За это отвечает переменная vm.overcommit_memory, так что лучше будет изменить параметры ядра Linux:
```shell
echo 2 > /proc/sys/vm/panic_on_oom
```

По умолчанию стоит 0. При значении 1 ядро всегда будет резервировать лишнюю память. Это рискованно.

При значении 2 ядро не будет резервировать больше памяти, чем указано в параметре `overcommit_ratio` в `/proc/sys/vm/overcommit_ratio`

---